{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66beefde",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-02-14T12:06:39.247524Z",
     "iopub.status.busy": "2026-02-14T12:06:39.246607Z",
     "iopub.status.idle": "2026-02-14T12:06:40.426135Z",
     "shell.execute_reply": "2026-02-14T12:06:40.425011Z"
    },
    "papermill": {
     "duration": 1.18705,
     "end_time": "2026-02-14T12:06:40.428458",
     "exception": false,
     "start_time": "2026-02-14T12:06:39.241408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/datasets/dimaspashaakrilian/dsc-itb/Data_Klaim.csv\n",
      "/kaggle/input/datasets/dimaspashaakrilian/dsc-itb/sample_submission.csv\n",
      "/kaggle/input/datasets/dimaspashaakrilian/dsc-itb/Data_Polis.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d24b7aa",
   "metadata": {
    "papermill": {
     "duration": 0.002838,
     "end_time": "2026-02-14T12:06:40.434412",
     "exception": false,
     "start_time": "2026-02-14T12:06:40.431574",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DATA FOUNDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d346a50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T12:06:40.442941Z",
     "iopub.status.busy": "2026-02-14T12:06:40.441889Z",
     "iopub.status.idle": "2026-02-14T12:06:40.685515Z",
     "shell.execute_reply": "2026-02-14T12:06:40.684304Z"
    },
    "papermill": {
     "duration": 0.250651,
     "end_time": "2026-02-14T12:06:40.687794",
     "exception": false,
     "start_time": "2026-02-14T12:06:40.437143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Klaim : (4627, 13)\n",
      "Initial Polis : (4096, 6)\n",
      "After merge : (4614, 19)\n",
      "Month range: 2024-01 → 2025-07\n",
      "\n",
      "Final shape: (4614, 27)\n",
      "Unique months: 19\n",
      "\n",
      "Sample:\n",
      "   claim_id nomor_polis reimburse_cashless inpatient_outpatient icd_diagnosis  \\\n",
      "0  C-0001-M    POL-0176                  R                   OP           C50   \n",
      "1  C-0002-M    POL-3288                  R                   OP           C34   \n",
      "2  C-0003-M    POL-1786                  R                   OP         C18.9   \n",
      "3  C-0004-M    POL-1786                  R                   OP           C34   \n",
      "4  C-0005-M    POL-2778                  R                   OP           C50   \n",
      "\n",
      "                           icd_description status_klaim  \\\n",
      "0             MALIGNANT NEOPLASM OF BREAST         PAID   \n",
      "1  MALIGNANT NEOPLASM OF BRONCHUS AND LUNG         PAID   \n",
      "2   MALIGNANT NEOPLASM, COLON, UNSPECIFIED         PAID   \n",
      "3  MALIGNANT NEOPLASM OF BRONCHUS AND LUNG         PAID   \n",
      "4             MALIGNANT NEOPLASM OF BREAST         PAID   \n",
      "\n",
      "  tanggal_pembayaran_klaim tanggal_pasien_masuk_rs tanggal_pasien_keluar_rs  \\\n",
      "0               2024-07-08              2024-05-27               2024-05-27   \n",
      "1               2024-08-06              2024-07-15               2024-07-15   \n",
      "2               2024-10-17              2024-05-16               2024-05-16   \n",
      "3               2024-09-03              2024-07-18               2024-07-18   \n",
      "4                      NaT              2024-06-06               2024-06-06   \n",
      "\n",
      "   ...  tanggal_efektif_polis    domisili year_month        age tenure_days  \\\n",
      "0  ...             2015-01-09     JAKARTA    2024-05  57.304110        3426   \n",
      "1  ...             2012-06-19  YOGYAKARTA    2024-07  67.849315        4409   \n",
      "2  ...             2015-03-16    SURABAYA    2024-05  64.613699        3349   \n",
      "3  ...             2015-03-16    SURABAYA    2024-07  64.786301        3412   \n",
      "4  ...             2014-06-24     JAKARTA    2024-06  55.786301        3635   \n",
      "\n",
      "  los is_inpatient is_cashless rs_bucket exposure  \n",
      "0   0            0           0     NONID     4096  \n",
      "1   0            0           0     NONID     4096  \n",
      "2   0            0           0     NONID     4096  \n",
      "3   0            0           0     NONID     4096  \n",
      "4   0            0           0     NONID     4096  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "\n",
      "STAGE 1 COMPLETE — TOP VERSION READY\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BASE_PATH = \"/kaggle/input/datasets/dimaspashaakrilian/dsc-itb/\"\n",
    "\n",
    "klaim = pd.read_csv(BASE_PATH + \"Data_Klaim.csv\")\n",
    "polis = pd.read_csv(BASE_PATH + \"Data_Polis.csv\")\n",
    "\n",
    "print(\"Initial Klaim :\", klaim.shape)\n",
    "print(\"Initial Polis :\", polis.shape)\n",
    "\n",
    "# ============================================================\n",
    "# CLEAN COLUMN NAMES\n",
    "# ============================================================\n",
    "\n",
    "def clean_columns(df):\n",
    "    df.columns = (\n",
    "        df.columns\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(\" \", \"_\", regex=False)\n",
    "        .str.replace(\"/\", \"_\", regex=False)\n",
    "        .str.replace(\"-\", \"_\", regex=False)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "klaim = clean_columns(klaim)\n",
    "polis = clean_columns(polis)\n",
    "\n",
    "klaim = klaim.drop_duplicates().reset_index(drop=True)\n",
    "polis = polis.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# ============================================================\n",
    "# DATE PARSING\n",
    "# ============================================================\n",
    "\n",
    "for col in klaim.columns:\n",
    "    if \"tanggal\" in col:\n",
    "        klaim[col] = pd.to_datetime(klaim[col], errors=\"coerce\")\n",
    "\n",
    "for col in polis.columns:\n",
    "    if \"tanggal\" in col:\n",
    "        try:\n",
    "            polis[col] = pd.to_datetime(\n",
    "                polis[col].astype(str),\n",
    "                format=\"%Y%m%d\",\n",
    "                errors=\"raise\"\n",
    "            )\n",
    "        except:\n",
    "            polis[col] = pd.to_datetime(polis[col], errors=\"coerce\")\n",
    "\n",
    "# ============================================================\n",
    "# BASIC CLEANING (SAFE)\n",
    "# ============================================================\n",
    "\n",
    "klaim = klaim.dropna(subset=[\"nomor_polis\"])\n",
    "klaim = klaim.dropna(subset=[\"tanggal_pasien_masuk_rs\"])\n",
    "\n",
    "klaim = klaim[\n",
    "    klaim[\"nominal_klaim_yang_disetujui\"] > 0\n",
    "].copy()\n",
    "\n",
    "# FIX claim_ratio safely\n",
    "if \"nominal_biaya_rs_yang_terjadi\" in klaim.columns:\n",
    "    denom = klaim[\"nominal_biaya_rs_yang_terjadi\"].replace(0, np.nan)\n",
    "    klaim[\"claim_ratio\"] = (\n",
    "        klaim[\"nominal_klaim_yang_disetujui\"] / denom\n",
    "    )\n",
    "    klaim[\"claim_ratio\"] = (\n",
    "        klaim[\"claim_ratio\"]\n",
    "        .replace([np.inf, -np.inf], np.nan)\n",
    "        .clip(0, 5)\n",
    "        .fillna(klaim[\"claim_ratio\"].median())\n",
    "    )\n",
    "\n",
    "# ============================================================\n",
    "# MERGE\n",
    "# ============================================================\n",
    "\n",
    "df = klaim.merge(polis, on=\"nomor_polis\", how=\"left\")\n",
    "\n",
    "print(\"After merge :\", df.shape)\n",
    "\n",
    "# ============================================================\n",
    "# USE SERVICE MONTH (CRITICAL FIX)\n",
    "# ============================================================\n",
    "\n",
    "df[\"year_month\"] = df[\"tanggal_pasien_masuk_rs\"].dt.to_period(\"M\")\n",
    "\n",
    "print(\"Month range:\",\n",
    "      df[\"year_month\"].min(),\n",
    "      \"→\",\n",
    "      df[\"year_month\"].max())\n",
    "\n",
    "# ============================================================\n",
    "# FEATURE ENGINEERING\n",
    "# ============================================================\n",
    "\n",
    "# Age\n",
    "if \"tanggal_lahir\" in df.columns:\n",
    "    df[\"age\"] = (\n",
    "        (df[\"tanggal_pasien_masuk_rs\"] - df[\"tanggal_lahir\"]).dt.days / 365\n",
    "    )\n",
    "\n",
    "# Tenure\n",
    "if \"tanggal_efektif_polis\" in df.columns:\n",
    "    df[\"tenure_days\"] = (\n",
    "        (df[\"tanggal_pasien_masuk_rs\"] -\n",
    "         df[\"tanggal_efektif_polis\"]).dt.days\n",
    "    )\n",
    "\n",
    "# Length of Stay (handle NaT safely)\n",
    "if \"tanggal_pasien_keluar_rs\" in df.columns:\n",
    "    df[\"los\"] = (\n",
    "        df[\"tanggal_pasien_keluar_rs\"] -\n",
    "        df[\"tanggal_pasien_masuk_rs\"]\n",
    "    ).dt.days\n",
    "\n",
    "# ============================================================\n",
    "# SEGMENT FEATURES (FOR SEASONAL-YOY MODEL)\n",
    "# ============================================================\n",
    "\n",
    "df[\"is_inpatient\"] = (\n",
    "    df[\"inpatient_outpatient\"]\n",
    "    .astype(str)\n",
    "    .str.upper()\n",
    "    .str.startswith(\"IP\")\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "df[\"is_cashless\"] = (\n",
    "    df[\"reimburse_cashless\"]\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .eq(\"cashless\")\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "df[\"rs_bucket\"] = np.where(\n",
    "    df[\"lokasi_rs\"].astype(str).str.lower() == \"indonesia\",\n",
    "    \"ID\",\n",
    "    \"NONID\"\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# EXPOSURE (CORRECT RANGE)\n",
    "# ============================================================\n",
    "\n",
    "all_months = pd.period_range(\n",
    "    df[\"year_month\"].min(),\n",
    "    df[\"year_month\"].max(),\n",
    "    freq=\"M\"\n",
    ")\n",
    "\n",
    "exposure_list = []\n",
    "\n",
    "for m in all_months:\n",
    "    active = polis[\n",
    "        polis[\"tanggal_efektif_polis\"].dt.to_period(\"M\") <= m\n",
    "    ][\"nomor_polis\"].nunique()\n",
    "\n",
    "    exposure_list.append({\n",
    "        \"year_month\": m,\n",
    "        \"exposure\": active\n",
    "    })\n",
    "\n",
    "exposure_df = pd.DataFrame(exposure_list)\n",
    "\n",
    "df = df.merge(exposure_df, on=\"year_month\", how=\"left\")\n",
    "\n",
    "# ============================================================\n",
    "# FINAL CHECK\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nFinal shape:\", df.shape)\n",
    "print(\"Unique months:\", df[\"year_month\"].nunique())\n",
    "print(\"\\nSample:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nSTAGE 1 COMPLETE — TOP VERSION READY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcd3e77",
   "metadata": {
    "papermill": {
     "duration": 0.003118,
     "end_time": "2026-02-14T12:06:40.694044",
     "exception": false,
     "start_time": "2026-02-14T12:06:40.690926",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TIME-SERIES DATASET ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a4e108b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T12:06:40.702286Z",
     "iopub.status.busy": "2026-02-14T12:06:40.701307Z",
     "iopub.status.idle": "2026-02-14T12:06:40.793872Z",
     "shell.execute_reply": "2026-02-14T12:06:40.792152Z"
    },
    "papermill": {
     "duration": 0.099402,
     "end_time": "2026-02-14T12:06:40.796280",
     "exception": false,
     "start_time": "2026-02-14T12:06:40.696878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment Monthly Shape: (189, 7)\n",
      "\n",
      "Portfolio Monthly Shape: (19, 27)\n",
      "Time Range: 2024-01 → 2025-07\n",
      "\n",
      "Columns:\n",
      "['year_month', 'frequency', 'total_claim', 'exposure', 'avg_age', 'avg_tenure', 'avg_los', 'avg_claim_ratio', 'severity', 'year_month_dt', 'month', 'month_sin', 'month_cos', 'month_index', 'frequency_lag1', 'frequency_roll3', 'frequency_expanding', 'total_claim_lag1', 'total_claim_roll3', 'total_claim_expanding', 'severity_lag1', 'severity_roll3', 'severity_expanding', 'share_inpatient', 'share_cashless', 'share_inpatient_lag1', 'share_cashless_lag1']\n",
      "\n",
      "Preview:\n",
      "  year_month  frequency   total_claim  exposure    avg_age   avg_tenure  \\\n",
      "0    2024-01        299  2.026098e+10      4096  59.930627  3345.050167   \n",
      "1    2024-02        208  1.385965e+10      4096  58.807337  3348.644231   \n",
      "2    2024-03        278  1.431126e+10      4096  57.909796  3309.902878   \n",
      "3    2024-04        238  1.144106e+10      4096  56.926154  3380.004202   \n",
      "4    2024-05        263  1.221146e+10      4096  57.309849  3504.266160   \n",
      "\n",
      "    avg_los  avg_claim_ratio      severity year_month_dt  ...  \\\n",
      "0  1.602007         0.932780  6.776248e+07    2024-01-01  ...   \n",
      "1  1.557692         0.909291  6.663291e+07    2024-02-01  ...   \n",
      "2  1.503597         0.891701  5.147935e+07    2024-03-01  ...   \n",
      "3  1.193277         0.887397  4.807169e+07    2024-04-01  ...   \n",
      "4  1.193916         0.932202  4.643141e+07    2024-05-01  ...   \n",
      "\n",
      "   total_claim_lag1  total_claim_roll3  total_claim_expanding  severity_lag1  \\\n",
      "0      2.026098e+10       1.614396e+10           2.026098e+10   6.776248e+07   \n",
      "1      2.026098e+10       1.614396e+10           2.026098e+10   6.776248e+07   \n",
      "2      1.385965e+10       1.614396e+10           1.706031e+10   6.663291e+07   \n",
      "3      1.431126e+10       1.614396e+10           1.614396e+10   5.147935e+07   \n",
      "4      1.144106e+10       1.320399e+10           1.496824e+10   4.807169e+07   \n",
      "\n",
      "   severity_roll3  severity_expanding  share_inpatient  share_cashless  \\\n",
      "0    6.195825e+07        6.776248e+07         0.712375             0.0   \n",
      "1    6.195825e+07        6.776248e+07         0.673077             0.0   \n",
      "2    6.195825e+07        6.719770e+07         0.705036             0.0   \n",
      "3    6.195825e+07        6.195825e+07         0.672269             0.0   \n",
      "4    5.539465e+07        5.848661e+07         0.619772             0.0   \n",
      "\n",
      "   share_inpatient_lag1  share_cashless_lag1  \n",
      "0              0.712375                  0.0  \n",
      "1              0.712375                  0.0  \n",
      "2              0.673077                  0.0  \n",
      "3              0.705036                  0.0  \n",
      "4              0.672269                  0.0  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "\n",
      "STAGE 2 COMPLETE — SEGMENT MODEL READY\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# 1. SEGMENT MONTHLY DATASET (MAIN MODEL)\n",
    "# ============================================================\n",
    "\n",
    "seg_cols = [\n",
    "    \"plan_code\",\n",
    "    \"is_inpatient\",\n",
    "    \"is_cashless\",\n",
    "    \"rs_bucket\"\n",
    "]\n",
    "\n",
    "seg_monthly = (\n",
    "    df.groupby([\"year_month\"] + seg_cols)\n",
    "      .agg(\n",
    "          frequency=(\"claim_id\",\"count\"),\n",
    "          total_claim=(\"nominal_klaim_yang_disetujui\",\"sum\")\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "print(\"Segment Monthly Shape:\", seg_monthly.shape)\n",
    "\n",
    "# ============================================================\n",
    "# 2. PORTFOLIO MONTHLY (FOR ML BLEND)\n",
    "# ============================================================\n",
    "\n",
    "monthly = (\n",
    "    df.groupby(\"year_month\")\n",
    "      .agg(\n",
    "          frequency=(\"claim_id\",\"count\"),\n",
    "          total_claim=(\"nominal_klaim_yang_disetujui\",\"sum\"),\n",
    "          exposure=(\"exposure\",\"max\"),\n",
    "          avg_age=(\"age\",\"mean\"),\n",
    "          avg_tenure=(\"tenure_days\",\"mean\"),\n",
    "          avg_los=(\"los\",\"mean\"),\n",
    "          avg_claim_ratio=(\"claim_ratio\",\"mean\")\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "monthly = monthly.sort_values(\"year_month\").reset_index(drop=True)\n",
    "\n",
    "monthly[\"severity\"] = monthly[\"total_claim\"] / monthly[\"frequency\"]\n",
    "\n",
    "# ============================================================\n",
    "# 3. CALENDAR FEATURES\n",
    "# ============================================================\n",
    "\n",
    "monthly[\"year_month_dt\"] = monthly[\"year_month\"].dt.to_timestamp()\n",
    "monthly[\"month\"] = monthly[\"year_month_dt\"].dt.month\n",
    "monthly[\"month_sin\"] = np.sin(2*np.pi*monthly[\"month\"]/12)\n",
    "monthly[\"month_cos\"] = np.cos(2*np.pi*monthly[\"month\"]/12)\n",
    "\n",
    "monthly[\"month_index\"] = np.arange(len(monthly))\n",
    "\n",
    "# ============================================================\n",
    "# 4. CORE LAGS (MINIMAL BUT STRONG)\n",
    "# ============================================================\n",
    "\n",
    "for col in [\"frequency\",\"total_claim\",\"severity\"]:\n",
    "    monthly[f\"{col}_lag1\"] = monthly[col].shift(1)\n",
    "    monthly[f\"{col}_roll3\"] = monthly[col].shift(1).rolling(3).mean()\n",
    "    monthly[f\"{col}_expanding\"] = monthly[col].shift(1).expanding().mean()\n",
    "\n",
    "# ============================================================\n",
    "# 5. MIX FEATURES (IMPORTANT FOR BLEND)\n",
    "# ============================================================\n",
    "\n",
    "mix = (\n",
    "    df.groupby(\"year_month\")\n",
    "      .agg(\n",
    "          share_inpatient=(\"is_inpatient\",\"mean\"),\n",
    "          share_cashless=(\"is_cashless\",\"mean\"),\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "monthly = monthly.merge(mix, on=\"year_month\", how=\"left\")\n",
    "\n",
    "for col in [\"share_inpatient\",\"share_cashless\"]:\n",
    "    monthly[f\"{col}_lag1\"] = monthly[col].shift(1)\n",
    "\n",
    "# ============================================================\n",
    "# 6. DO NOT DROP MONTHS (FILL SMART)\n",
    "# ============================================================\n",
    "\n",
    "for col in monthly.columns:\n",
    "    if col not in [\"year_month\",\"year_month_dt\"]:\n",
    "        monthly[col] = monthly[col].fillna(method=\"bfill\")\n",
    "\n",
    "print(\"\\nPortfolio Monthly Shape:\", monthly.shape)\n",
    "print(\"Time Range:\",\n",
    "      monthly[\"year_month\"].min(),\n",
    "      \"→\",\n",
    "      monthly[\"year_month\"].max())\n",
    "\n",
    "print(\"\\nColumns:\")\n",
    "print(monthly.columns.tolist())\n",
    "\n",
    "print(\"\\nPreview:\")\n",
    "print(monthly.head())\n",
    "\n",
    "print(\"\\nSTAGE 2 COMPLETE — SEGMENT MODEL READY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1ae88c",
   "metadata": {
    "papermill": {
     "duration": 0.003232,
     "end_time": "2026-02-14T12:06:40.803413",
     "exception": false,
     "start_time": "2026-02-14T12:06:40.800181",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MODEL DEVELOPMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e15ab9fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T12:06:40.811455Z",
     "iopub.status.busy": "2026-02-14T12:06:40.811028Z",
     "iopub.status.idle": "2026-02-14T12:06:43.124630Z",
     "shell.execute_reply": "2026-02-14T12:06:43.123648Z"
    },
    "papermill": {
     "duration": 2.320726,
     "end_time": "2026-02-14T12:06:43.127275",
     "exception": false,
     "start_time": "2026-02-14T12:06:40.806549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE Frequency : 8.12\n",
      "MAPE Total     : 19.19\n",
      "MAPE Severity  : 16.1\n",
      "Estimated Score: 14.47\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "monthly = monthly.sort_values(\"year_month\").reset_index(drop=True)\n",
    "\n",
    "# =========================\n",
    "# CREATE RATE\n",
    "# =========================\n",
    "\n",
    "monthly[\"claim_rate\"] = monthly[\"frequency\"] / monthly[\"exposure\"]\n",
    "\n",
    "train_cut = pd.Period(\"2025-01\", freq=\"M\")\n",
    "\n",
    "train_data = monthly[monthly[\"year_month\"] < train_cut]\n",
    "valid_data = monthly[monthly[\"year_month\"] >= train_cut].iloc[:4]\n",
    "\n",
    "steps = 4\n",
    "\n",
    "# =========================\n",
    "# MODEL CLAIM RATE\n",
    "# =========================\n",
    "\n",
    "model_rate = ExponentialSmoothing(\n",
    "    train_data[\"claim_rate\"],\n",
    "    trend=\"add\",\n",
    "    damped_trend=True,\n",
    "    seasonal=None\n",
    ").fit()\n",
    "\n",
    "pred_rate = model_rate.forecast(steps)\n",
    "\n",
    "# =========================\n",
    "# MODEL SEVERITY (LOG)\n",
    "# =========================\n",
    "\n",
    "model_sev = ExponentialSmoothing(\n",
    "    np.log1p(train_data[\"severity\"]),\n",
    "    trend=\"add\",\n",
    "    damped_trend=True,\n",
    "    seasonal=None\n",
    ").fit()\n",
    "\n",
    "pred_sev = np.expm1(model_sev.forecast(steps))\n",
    "\n",
    "# =========================\n",
    "# RECONSTRUCT\n",
    "# =========================\n",
    "\n",
    "exposure_future = valid_data[\"exposure\"].values\n",
    "\n",
    "pred_freq = pred_rate * exposure_future\n",
    "pred_freq = np.clip(pred_freq, 1, None)\n",
    "\n",
    "pred_total = pred_freq * pred_sev\n",
    "\n",
    "# =========================\n",
    "# TRUE VALUES\n",
    "# =========================\n",
    "\n",
    "true_freq = valid_data[\"frequency\"].values\n",
    "true_total = valid_data[\"total_claim\"].values\n",
    "true_sev = valid_data[\"severity\"].values\n",
    "\n",
    "print(\"MAPE Frequency :\", round(mape(true_freq,pred_freq),2))\n",
    "print(\"MAPE Total     :\", round(mape(true_total,pred_total),2))\n",
    "print(\"MAPE Severity  :\", round(mape(true_sev,pred_sev),2))\n",
    "print(\"Estimated Score:\",\n",
    "      round((mape(true_freq,pred_freq)+\n",
    "             mape(true_total,pred_total)+\n",
    "             mape(true_sev,pred_sev))/3,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f9eca9",
   "metadata": {
    "papermill": {
     "duration": 0.004846,
     "end_time": "2026-02-14T12:06:43.137053",
     "exception": false,
     "start_time": "2026-02-14T12:06:43.132207",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TOTAL CLAIM OPTIMIZATION & VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f83d529f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T12:06:43.149888Z",
     "iopub.status.busy": "2026-02-14T12:06:43.148811Z",
     "iopub.status.idle": "2026-02-14T12:06:43.768458Z",
     "shell.execute_reply": "2026-02-14T12:06:43.767572Z"
    },
    "papermill": {
     "duration": 0.629006,
     "end_time": "2026-02-14T12:06:43.771034",
     "exception": false,
     "start_time": "2026-02-14T12:06:43.142028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Individual Total MAPE:\n",
      "Actuarial : 0.1919\n",
      "Ridge : 0.2227\n",
      "Holt : 0.188\n",
      "\n",
      "FINAL COMPETITION SCORE\n",
      "MAPE Frequency : 0.0812\n",
      "MAPE Severity  : 0.161\n",
      "MAPE Total     : 0.1853\n",
      "Final Score    : 0.1425\n",
      "\n",
      "STAGE 4 COMPLETE — FULL SELF CONTAINED\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# IMPORT\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# ============================================================\n",
    "# SAFE MAPE\n",
    "# ============================================================\n",
    "\n",
    "def safe_mape(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask]))\n",
    "\n",
    "# ============================================================\n",
    "# SPLIT\n",
    "# ============================================================\n",
    "\n",
    "monthly = monthly.sort_values(\"year_month\").reset_index(drop=True)\n",
    "\n",
    "train_cut = pd.Period(\"2025-01\", freq=\"M\")\n",
    "\n",
    "train = monthly[monthly[\"year_month\"] < train_cut].copy()\n",
    "valid = monthly[monthly[\"year_month\"] >= train_cut].iloc[:4].copy()\n",
    "\n",
    "# ============================================================\n",
    "# 1️⃣ FREQUENCY MODEL (HOLT DAMPED)\n",
    "# ============================================================\n",
    "\n",
    "model_freq = ExponentialSmoothing(\n",
    "    train[\"frequency\"],\n",
    "    trend=\"add\",\n",
    "    damped_trend=True,\n",
    "    seasonal=None\n",
    ").fit()\n",
    "\n",
    "freq_pred_valid = model_freq.forecast(len(valid))\n",
    "freq_pred_valid = np.clip(freq_pred_valid, 1, None)\n",
    "\n",
    "# ============================================================\n",
    "# 2️⃣ SEVERITY MODEL (LOG HOLT)\n",
    "# ============================================================\n",
    "\n",
    "model_sev = ExponentialSmoothing(\n",
    "    np.log1p(train[\"severity\"]),\n",
    "    trend=\"add\",\n",
    "    damped_trend=True,\n",
    "    seasonal=None\n",
    ").fit()\n",
    "\n",
    "sev_pred_valid = np.expm1(model_sev.forecast(len(valid)))\n",
    "sev_pred_valid = np.clip(sev_pred_valid, 1, None)\n",
    "\n",
    "# ============================================================\n",
    "# 3️⃣ ACTUARIAL TOTAL\n",
    "# ============================================================\n",
    "\n",
    "total_pred_valid_actuarial = freq_pred_valid * sev_pred_valid\n",
    "\n",
    "# ============================================================\n",
    "# 4️⃣ RIDGE TOTAL\n",
    "# ============================================================\n",
    "\n",
    "features_total = [\n",
    "    \"month_index\",\n",
    "    \"month_sin\",\n",
    "    \"month_cos\",\n",
    "    \"total_lag1\",\n",
    "    \"frequency_lag1\",\n",
    "    \"severity_lag1\"\n",
    "]\n",
    "\n",
    "features_total = [f for f in features_total if f in monthly.columns]\n",
    "\n",
    "X_train_total = train[features_total]\n",
    "X_valid_total = valid[features_total]\n",
    "\n",
    "y_train_total = np.log1p(train[\"total_claim\"])\n",
    "y_valid_total = valid[\"total_claim\"]\n",
    "\n",
    "ridge_total = Ridge(alpha=50)\n",
    "ridge_total.fit(X_train_total, y_train_total)\n",
    "\n",
    "total_pred_valid_ridge = np.expm1(ridge_total.predict(X_valid_total))\n",
    "total_pred_valid_ridge = np.clip(total_pred_valid_ridge, 1, None)\n",
    "\n",
    "# ============================================================\n",
    "# 5️⃣ HOLT TOTAL\n",
    "# ============================================================\n",
    "\n",
    "holt_model = ExponentialSmoothing(\n",
    "    train[\"total_claim\"],\n",
    "    trend=\"add\",\n",
    "    damped_trend=True,\n",
    "    seasonal=None\n",
    ").fit()\n",
    "\n",
    "total_pred_valid_holt = holt_model.forecast(len(valid))\n",
    "total_pred_valid_holt = np.clip(total_pred_valid_holt, 1, None)\n",
    "\n",
    "# ============================================================\n",
    "# 6️⃣ EVALUATE INDIVIDUAL\n",
    "# ============================================================\n",
    "\n",
    "models = {\n",
    "    \"Actuarial\": total_pred_valid_actuarial,\n",
    "    \"Ridge\": total_pred_valid_ridge,\n",
    "    \"Holt\": total_pred_valid_holt\n",
    "}\n",
    "\n",
    "print(\"\\nIndividual Total MAPE:\")\n",
    "for k, v in models.items():\n",
    "    print(k, \":\", round(safe_mape(y_valid_total, v), 4))\n",
    "\n",
    "# ============================================================\n",
    "# 7️⃣ STABLE FIXED BLEND\n",
    "# ============================================================\n",
    "\n",
    "weights = {\n",
    "    \"Actuarial\": 0.5,\n",
    "    \"Ridge\": 0.25,\n",
    "    \"Holt\": 0.25\n",
    "}\n",
    "\n",
    "total_pred_valid_blend = sum(\n",
    "    weights[k] * models[k] for k in models\n",
    ")\n",
    "\n",
    "mape_total_final = safe_mape(y_valid_total, total_pred_valid_blend)\n",
    "\n",
    "# ============================================================\n",
    "# 8️⃣ FINAL SCORE\n",
    "# ============================================================\n",
    "\n",
    "mape_freq_final = safe_mape(valid[\"frequency\"], freq_pred_valid)\n",
    "mape_sev_final  = safe_mape(valid[\"severity\"], sev_pred_valid)\n",
    "\n",
    "final_score = (mape_freq_final + mape_sev_final + mape_total_final) / 3\n",
    "\n",
    "print(\"\\nFINAL COMPETITION SCORE\")\n",
    "print(\"MAPE Frequency :\", round(mape_freq_final, 4))\n",
    "print(\"MAPE Severity  :\", round(mape_sev_final, 4))\n",
    "print(\"MAPE Total     :\", round(mape_total_final, 4))\n",
    "print(\"Final Score    :\", round(final_score, 4))\n",
    "\n",
    "print(\"\\nSTAGE 4 COMPLETE — FULL SELF CONTAINED\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf69fc9",
   "metadata": {
    "papermill": {
     "duration": 0.004886,
     "end_time": "2026-02-14T12:06:43.781956",
     "exception": false,
     "start_time": "2026-02-14T12:06:43.777070",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TEST PREDICTION & KAGGLE SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc34e3c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T12:06:43.794375Z",
     "iopub.status.busy": "2026-02-14T12:06:43.793661Z",
     "iopub.status.idle": "2026-02-14T12:06:43.917227Z",
     "shell.execute_reply": "2026-02-14T12:06:43.915279Z"
    },
    "papermill": {
     "duration": 0.13287,
     "end_time": "2026-02-14T12:06:43.919799",
     "exception": false,
     "start_time": "2026-02-14T12:06:43.786929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All IDs matched successfully.\n",
      "\n",
      "Submission file created.\n",
      "                        id         value\n",
      "0  2025_08_Claim_Frequency  2.353129e+02\n",
      "1   2025_08_Claim_Severity  5.291305e+07\n",
      "2      2025_08_Total_Claim  1.252789e+10\n",
      "3  2025_09_Claim_Frequency  2.352243e+02\n",
      "4   2025_09_Claim_Severity  5.289162e+07\n",
      "5      2025_09_Total_Claim  1.251231e+10\n",
      "6  2025_10_Claim_Frequency  2.351535e+02\n",
      "7   2025_10_Claim_Severity  5.287449e+07\n",
      "8      2025_10_Total_Claim  1.249910e+10\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STAGE 5 — FINAL SUBMISSION CLEAN\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "BASE_PATH = \"/kaggle/input/datasets/dimaspashaakrilian/dsc-itb/\"\n",
    "sample_sub = pd.read_csv(BASE_PATH + \"sample_submission.csv\")\n",
    "\n",
    "# ============================================================\n",
    "# PREPARE FULL DATA (TRAIN ALL HISTORY)\n",
    "# ============================================================\n",
    "\n",
    "monthly = monthly.sort_values(\"year_month\").reset_index(drop=True)\n",
    "\n",
    "# Refit models on FULL data (sampai Jul 2025)\n",
    "\n",
    "model_freq_full = ExponentialSmoothing(\n",
    "    monthly[\"frequency\"],\n",
    "    trend=\"add\",\n",
    "    damped_trend=True,\n",
    "    seasonal=None\n",
    ").fit()\n",
    "\n",
    "model_sev_full = ExponentialSmoothing(\n",
    "    np.log1p(monthly[\"severity\"]),\n",
    "    trend=\"add\",\n",
    "    damped_trend=True,\n",
    "    seasonal=None\n",
    ").fit()\n",
    "\n",
    "model_total_full = ExponentialSmoothing(\n",
    "    monthly[\"total_claim\"],\n",
    "    trend=\"add\",\n",
    "    damped_trend=True,\n",
    "    seasonal=None\n",
    ").fit()\n",
    "\n",
    "# ============================================================\n",
    "# EXTRACT FUTURE MONTHS\n",
    "# ============================================================\n",
    "\n",
    "sample_sub[\"year\"]  = sample_sub[\"id\"].str.split(\"_\").str[0]\n",
    "sample_sub[\"month\"] = sample_sub[\"id\"].str.split(\"_\").str[1]\n",
    "sample_sub[\"month_key\"] = sample_sub[\"year\"] + \"-\" + sample_sub[\"month\"]\n",
    "\n",
    "future_periods = (\n",
    "    pd.PeriodIndex(sample_sub[\"month_key\"], freq=\"M\")\n",
    "      .unique()\n",
    "      .sort_values()\n",
    ")\n",
    "\n",
    "steps = len(future_periods)\n",
    "\n",
    "# ============================================================\n",
    "# FORECAST (CONVERT TO NUMPY)\n",
    "# ============================================================\n",
    "\n",
    "freq_forecast = np.array(model_freq_full.forecast(steps))\n",
    "freq_forecast = np.clip(freq_forecast, 1, None)\n",
    "\n",
    "sev_forecast = np.array(np.expm1(model_sev_full.forecast(steps)))\n",
    "sev_forecast = np.clip(sev_forecast, 1, None)\n",
    "\n",
    "total_actuarial = freq_forecast * sev_forecast\n",
    "\n",
    "total_holt = np.array(model_total_full.forecast(steps))\n",
    "total_holt = np.clip(total_holt, 1, None)\n",
    "\n",
    "# Stable blend\n",
    "total_forecast = 0.6 * total_actuarial + 0.4 * total_holt\n",
    "\n",
    "# ============================================================\n",
    "# STABLE BLEND (FIXED)\n",
    "# ============================================================\n",
    "\n",
    "# 60% actuarial + 40% holt (lebih stabil)\n",
    "total_forecast = 0.6 * total_actuarial + 0.4 * total_holt\n",
    "\n",
    "# ============================================================\n",
    "# BUILD SUBMISSION\n",
    "# ============================================================\n",
    "\n",
    "predictions = {}\n",
    "\n",
    "for i, period in enumerate(future_periods):\n",
    "\n",
    "    key = f\"{period.year}_{str(period.month).zfill(2)}\"\n",
    "\n",
    "    predictions[f\"{key}_Claim_Frequency\"] = freq_forecast[i]\n",
    "    predictions[f\"{key}_Claim_Severity\"]  = sev_forecast[i]\n",
    "    predictions[f\"{key}_Total_Claim\"]     = total_forecast[i]\n",
    "\n",
    "submission = sample_sub.copy()\n",
    "submission[\"value\"] = submission[\"id\"].map(predictions)\n",
    "\n",
    "if submission[\"value\"].isna().sum() > 0:\n",
    "    print(\"ERROR: Some IDs not matched\")\n",
    "else:\n",
    "    print(\"All IDs matched successfully.\")\n",
    "\n",
    "submission = submission[[\"id\", \"value\"]]\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"\\nSubmission file created.\")\n",
    "print(submission.head(9))\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 9488145,
     "sourceId": 14836320,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.749793,
   "end_time": "2026-02-14T12:06:47.119833",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-14T12:06:35.370040",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
